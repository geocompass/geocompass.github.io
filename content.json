{"meta":{"title":"国信司南技术团队博客","subtitle":"系统工程二部","description":"团队技术博客","author":"Geo-Compass","url":"http://geocompass.github.io","root":"/"},"pages":[],"posts":[{"title":"格林威治转东八区格式工具","slug":"frontend/GreenwichToEasteight.tool","date":"2019-09-23T16:00:00.000Z","updated":"2020-05-21T01:10:32.134Z","comments":true,"path":"2019/09/24/frontend/GreenwichToEasteight.tool/","link":"","permalink":"http://geocompass.github.io/2019/09/24/frontend/GreenwichToEasteight.tool/","excerpt":"","text":"一、关于工具1.1 问题 中国的标准时间为格林威治时间 + 8 转换后的格式问题1.2 需求 我们可能想要的转化格式 2017-08-27 22:40:21 2017/08/27 22:401.3 应用code/** * 格林威治时间转东八区 * newdata 需要转化的格林威治时间，例如\"2019-09-24T00:41:41.201Z\" * format 转化后的格式，默认\"yyyy-MM-dd hh:mm:ss\"*/const GreenwichToEasteight = (newdata, format = \"yyyy/MM/dd hh:mm\") =&gt; &#123; let that = new Date(newdata); let o = &#123; \"M+\": that.getMonth() + 1, //月份 \"d+\": that.getDate(), //日 \"h+\": that.getHours(), //小时 \"m+\": that.getMinutes(), //分 \"s+\": that.getSeconds(), //秒 \"q+\": Math.floor((that.getMonth() + 3) / 3), //季度 S: that.getMilliseconds() &#125;; if (/(y+)/.test(format)) format = format.replace( RegExp.$1, (that.getFullYear() + \"\").substr(4 - RegExp.$1.length) ); for (let k in o) if (new RegExp(\"(\" + k + \")\").test(format)) format = format.replace( RegExp.$1, RegExp.$1.length == 1 ? o[k] : (\"00\" + o[k]).substr((\"\" + o[k]).length) ); return format;&#125;;export default GreenwichToEasteight; 1.4 使用import GreenwichToEasteight from \"\";GreenwichToEasteight(\"2019-09-24T00:41:41.201Z\") // \"2019-09-24 08:41:41\"GreenwichToEasteight(\"2019-09-24T00:41:41.201Z\", \"yyyy/MM/dd hh:mm\") // \"2019/09/24 08:41\"","categories":[{"name":"前端","slug":"前端","permalink":"http://geocompass.github.io/categories/前端/"}],"tags":[{"name":"前端工具","slug":"前端工具","permalink":"http://geocompass.github.io/tags/前端工具/"}],"author":"LOUSANPANG"},{"title":"前端工具-defineProperty实时监听globalState值的变化","slug":"frontend/DefineProperty.tool","date":"2019-09-04T16:00:00.000Z","updated":"2020-05-21T01:10:32.114Z","comments":true,"path":"2019/09/05/frontend/DefineProperty.tool/","link":"","permalink":"http://geocompass.github.io/2019/09/05/frontend/DefineProperty.tool/","excerpt":"","text":"一、关于工具1.1 问题 在 react、taro、微信小程序 中如何做到像 vue的watch方法 一样去监听属性的变化？ 虽然在 taro、微信小程序 中的 app.js 中微信小程序的onLaunch taro的componentDidMount 生命周期快于各个page页面的生命周期，但是在app.js的onLaunch或componentDidMount中存在异步且执行时间很长的服务或者延时，那在page中的生命周期执行的函数可就不一定在它之后执行了。 1.2 需求 预期行为 实际行为 1.3 解决 使用同步async await去解决异步、延时等问题（缺点：使用同步就必须在同一个生命周期中去等待，造成代码赘余，不方便在各个页面使用。） 使用Redux Mobx数据管理工具（缺点：如果不是很多的跨组件数据监听，显的过于沉重。） 使用Object.defineProperty去实时监听state、globalState对象中的属性的变化。1.4 使用// app.jsglobalData: &#123; name: ''&#125;,onLaunch() &#123; let obj = this.globalData setTimeout(() =&gt; &#123; obj.name // 读取 obj.name = 'lousanpang' // 设置 &#125;, 2000)&#125; // index.js$watch() &#123; let obj = app.globalData Object.defineProperty(obj, \"name\", &#123; configurable: true, enumerable: true, get() &#123; // 在onLaunch中读取obj.name时会触发get函数 console.log('%c get读取成功!', 'background:#1976D2;color:#ffffff') &#125;, set(value) &#123; // 在onLaunch中设置obj.name时会触发set函数 console.log(`%c set设置成功: $&#123;value&#125;`, 'background:#ff4400;color:#ffffff') &#125; &#125;);&#125;onLoad: function(options) &#123; let obj = app.globalData this.$watch()&#125; 二、 拓展defineProperty2.1 语法 语法Object.defineProperty(obj, prop, descriptor) 参数说明： obj：必需。目标对象prop：必需。需定义或修改的属性的名字descriptor：必需。目标属性所拥有的特性 descriptor 包含数据描述、存取器描述，6个属性 数据描述 value: 设置属性的值 writable: 值是否可以重写。true | false enumerable: 目标属性是否可以被枚举。true | false configurable: 目标属性是否可以被删除或是否可以再次修改特性 true | false 存取器描述 get:function ()&#123;&#125; | undefined, set:function (value)&#123;&#125; | undefined 注意：当使用了getter或setter方法，不允许使用writable和value这两个属性 2.2 使用 数据描述 let obj = &#123;&#125;Object.defineProperty(obj, \"name\", &#123; value: \"lousanpang\", writable: true, enumerable: true, configurable: true&#125;);// 读取console.log( obj.name ); // lousanpang//枚举对象的属性for( var val in obj )&#123; console.log( val ); // lousanpang&#125;// 删除delete obj.name;console.log( obj.name ); // undefined 存取器描述 let obj = &#123; name: ''&#125;;Object.defineProperty(obj, \"name\", &#123; get() &#123; //当获取值的时候触发 conosle.log('get!') &#125;, set(value) &#123; //当设置值的时候触发,设置的新值通过参数value拿到 console.log(value) &#125;&#125;);console.log( obj.name ); // 获取值 ''obj.name = 'lousanpang'; // 设置值console.log( obj.name ); // lousanpang// 触发set 打印value--lousanpang 三、Object.defineProperty","categories":[{"name":"前端","slug":"前端","permalink":"http://geocompass.github.io/categories/前端/"}],"tags":[{"name":"前端工具","slug":"前端工具","permalink":"http://geocompass.github.io/tags/前端工具/"},{"name":"react","slug":"react","permalink":"http://geocompass.github.io/tags/react/"},{"name":"taro","slug":"taro","permalink":"http://geocompass.github.io/tags/taro/"},{"name":"小程序","slug":"小程序","permalink":"http://geocompass.github.io/tags/小程序/"}],"author":"LOUSANPANG"},{"title":"更快捷的PG+PostGIS转换火星坐标系方法","slug":"database/更快捷的PG-PostGIS转换火星坐标系方法","date":"2019-08-22T06:38:14.000Z","updated":"2020-05-21T01:10:32.113Z","comments":true,"path":"2019/08/22/database/更快捷的PG-PostGIS转换火星坐标系方法/","link":"","permalink":"http://geocompass.github.io/2019/08/22/database/更快捷的PG-PostGIS转换火星坐标系方法/","excerpt":"","text":"本文作者：yikouning注：转载请标明出处 关于坐标系我们通常用经纬度来表示一个地理位置，但是由于一些原因，我们从不同渠道得到的经纬度信息可能并不是在同一个坐标系下。 高德地图、腾讯地图以及谷歌中国区地图使用的是GCJ-02坐标系 百度地图使用的是BD-09坐标系 底层接口(HTML5 Geolocation或ios、安卓API)通过GPS设备获取的坐标使用的是WGS-84坐标系 不同的坐标系之间可能有几十到几百米的偏移，所以在开发基于地图的产品，或者做地理数据可视化时，我们需要修正不同坐标系之间的偏差。 WGS-84 - 世界大地测量坐标系WGS-84（World Geodetic System, WGS）是使用最广泛的坐标系，也是世界通用的坐标系，GPS设备得到的经纬度就是在WGS84坐标系下的经纬度。通常通过底层接口得到的定位信息都是WGS84坐标系。如天地图，osm底图等。 GCJ-02 - 国测局坐标系GCJ-02（G-Guojia国家，C-Cehui测绘，J-Ju局），又被称为火星坐标系，是一种基于WGS-84制定的大地测量系统，由中国国测局制定。此坐标系所采用的混淆算法会在经纬度中加入随机的偏移。如谷歌地图（中国区），高德地图，腾讯地图等。 BD-09 - 百度坐标系系BD-09（Baidu, BD）是百度地图使用的地理坐标系，其在GCJ-02基础上又增加了一次偏移，用来保护用户隐私。从百度产品中得到的坐标都是BD-09坐标系。 如何安装PostgreSQL安装PostGIS扩展复制geoc-pg-coordtansform.sql中代码，在数据库执行github地址：https://github.com/geocompass/pg-coordtransform 示例GCJ02转WGS84select geoc_gcj02towgs84(geom) from test_tableWGS84转GCJ02select geoc_wgs84togcj02(geom) from test_tableWGS84转BD09select geoc_wgs84tobd09(geom) from test_tableBD09转WGS84select geoc_bd09towgs84(geom) from test_tableGCJ02转BD09select geoc_gcj02tobd09(geom) from test_tableBD09转GCJ02select geoc_bd09togcj02(geom) from test_table 转换方法基于 PG+PostGIS 进行三种坐标系之间的转换，支持点、线、面、多点、多线、多面等各种需求进行互转 geoc_gcj02towgs84：火星坐标系转WGS84坐标系geoc_wgs84togcj02：WGS84坐标系转火星坐标系geoc_wgs84tobd09：WGS84坐标系转百度坐标系geoc_bd09towgs84：百度坐标系转WGS84坐标系geoc_gcj02tobd09：火星坐标系转百度坐标系geoc_bd09togcj02：百度坐标系转火星坐标系 注意事项传入的geometry参数的 SRID 必须是 4326 或 4490 ，否则返回null。 注本文如对您有帮助，请在 github 上 star 一下","categories":[{"name":"数据库","slug":"数据库","permalink":"http://geocompass.github.io/categories/数据库/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://geocompass.github.io/tags/PostgreSQL/"},{"name":"PostGIS","slug":"PostGIS","permalink":"http://geocompass.github.io/tags/PostGIS/"}],"author":null},{"title":"前端工具-距离转换标题缩写","slug":"frontend/DistanceTitle.tool","date":"2019-08-21T16:00:00.000Z","updated":"2020-05-21T01:10:32.115Z","comments":true,"path":"2019/08/22/frontend/DistanceTitle.tool/","link":"","permalink":"http://geocompass.github.io/2019/08/22/frontend/DistanceTitle.tool/","excerpt":"","text":"一、关于工具1.1 问题 地图展示出来的距离不符合我们展示的要求例如：0.01km 1.001km 对应地图信息标题展示内容过长例如：北京市海淀区车道沟1号青东商务区1.2 需求 我们可能想要的距离 10m 1.0km 我们想要的标题 北京市...青东商务区1.3 应用const StrEllipsis = (str, len, starlen = 0, endlen = 0) =&gt; &#123; if (str.length &gt; len) &#123; return str.substr(0, starlen) + \"...\" + str.substr(str.length - endlen, str.length); &#125; return str;&#125;;const StrKm = (juli, fixednum = 3) =&gt; &#123; if (parseInt(juli) == juli) &#123; return juli + 'km' &#125; else &#123; let left = juli.toString().split(\".\")[0] let leftlast = left[left.length-1] if (left.length == 1 &amp;&amp; leftlast == 0) &#123; return juli.toFixed(fixednum)*(10 ** fixednum) + 'm' &#125; else &#123; return juli.toFixed(1) + 'km' &#125; &#125;&#125;export &#123; StrEllipsis, StrKm&#125; 1.4 使用import &#123;StrEllipsis, StrKm&#125; from ''StrEllipsis('北京市海淀区车道沟1号青东商务区', 8, 3, 5) // '北京市...青东商务区'StrEllipsis('北京市海淀区车道沟1号青东商务区', 30) // '北京市海淀区车道沟1号青东商务区'StrKm(0.01) // 10mStrKm(1.01) // 1.0kmStrKm(0.123456) // 123m","categories":[{"name":"前端","slug":"前端","permalink":"http://geocompass.github.io/categories/前端/"}],"tags":[{"name":"前端工具","slug":"前端工具","permalink":"http://geocompass.github.io/tags/前端工具/"},{"name":"地图工具","slug":"地图工具","permalink":"http://geocompass.github.io/tags/地图工具/"}],"author":"LOUSANPANG"},{"title":"Egg.js打包","slug":"backend/Egg-js打包","date":"2019-08-21T12:31:05.000Z","updated":"2020-05-21T01:10:32.109Z","comments":true,"path":"2019/08/21/backend/Egg-js打包/","link":"","permalink":"http://geocompass.github.io/2019/08/21/backend/Egg-js打包/","excerpt":"","text":"本文由 @小刘 原创，转载请注明出处。 &nbsp; &nbsp; &nbsp; &nbsp;github示例地址：https://github.com/MrSmallLiu/pkg-egg-example &nbsp; &nbsp; &nbsp; &nbsp;打包Node.js代码的工具有很多，有些工具在打包时将自己写的代码打包为二进制文件配合node_modules一起使用，有些工具将全部代码打包为二进制，个人比较偏向于全部打包，例如pkg，都可以支持express、koa等框架打包，但是对于将koa框架封装后的Egg.js框架打包都没有说明如何使用，我在多次尝试后，加之阅读一部分Egg.js源码后终于利用pkg成功的打包。如下介绍如何利用pkg打包Egg.js代码。 利用pkg打包Egg.js代码（上面嘟囔了一堆废话，终于步入正题。） pkg是将整个工程打包为一个二进制文件，包括node运行环境一起打包，非常方便迁移，而且不需要客户环境重新部署Node.js以及下载相关依赖，具体步骤如下： 安装pkg(参考pkg) npm install pkg -g 配置Egg.js的public路径。由于打包后为二进制文件，对于某些用户将前端代码放在Egg.js工程目录下的将不能操作，于是修改Egg.js的public路径配置到运行路径下： // 修改config/config.default.jsconfig.static = &#123; prefix: '/', dir: process.cwd() + '/public' &#125; 配置Egg.js的运行时路径。由于Egg.js运行时会生成run文件夹以及相关文件，而pkg打包后为二进制文件，不能在继续进行写操作，故将rundir配置到运行路径下： //修改config/config.default.jsconfig.rundir = process.cwd() + '/run' 修改package.json配置pkg相关参数： 将代码以静态文件方式添加到打包中： //修改package.json，增加pkg节点\"pkg\": &#123; \"assets\": [ \"./config/*.js\", \"./app.js\", \"./app/**/*.js\", \"./node_modules/nanoid/**/*.js\" //该行为必须添加，由于Egg.js使用nanoid库，其中用到一个文件pkg未能解析，于是手动添加 ] &#125; 配置pkg入口： // 修改package.json，增加bin节点，指定入口文件\"bin\": \"build.js\"// build.js文件内容require(__dirname + '/node_modules/egg-scripts/bin/egg-scripts.js') 配置build命令 // 修改package.json,在scripts下增加build命令\"scripts\": &#123; \"build\": \"pkg . --targets node8-linux-x64 --out-path /usr/dist --debug\" &#125;// --targets 指定node版本为8以及linux-x64// --out-path 指定打包后文件输出路径// --debug 指定debug模式编译 开始打包// 初次打包时间较长，后续打包pkg会使用node缓存，提高打包效率npm run build 运行./test_pkg start /snapshot/test_pkg --port=9001 --title=test_pkg// ./test_pkg 打包后的二进制文件// /snapshot/test_pkg 其中/snapshot为必须路径，test_pkg为工程目录路径// --port --title等支持与平常启动时的任意命令参数 以上即完成了Egg.js的项目打包工作，这时可能有人会想到数据库相关配置怎么动态来改变呢？ C++编译的模块能否支持打包呢？，那请继续阅读。 扩展如何支持动态config可能有人会想到利用Egg.js的启动周期来做呀，那么说对了，就是利用configWillLoad周期来做，在项目中创建app.js文件（如果已经有的请忽略），利用周期读取外部config.js，然后替换config/config.default.js内容，示例代码如下： // 替换sequelize的storage，替换dataPath路径var fs = require('fs');class AppBootHook &#123; constructor(app) &#123; this.app = app; &#125; configWillLoad() &#123; let customConfig = require(process.cwd() + '/config.js'); this.app.config.sequelize.storage = customConfig.dbPath; this.app.config.dataPath = customConfig.dataPath; &#125;&#125; module.exports = AppBootHook; 注意Node.js大部分用户应该都会使用sequelize，而对于Egg.js使用egg-sequelize，由于egg-sequelize周期中包含agent.js，启动时读取config/config.default.js，会导致启动失败，于是本人修改了一版egg-sequelize_pkg用于打包使用，除配置名称差异外使用方法与egg-sequelize一致，不需要修改原有代码,如下配置更改即可 // &#123;app_root&#125;/config/plugin.jsexports.sequelizePkg = &#123; enable: true, package: 'egg-sequelize_pkg',&#125;;// &#123;app_root&#125;/config/config.default.jsexports.sequelizePkg = &#123;&#125;; github地址为：https://github.com/MrSmallLiu/egg-sequelize_pkg 欢迎提问题，也欢迎star C++模块引入pkg介绍对于C++编译的.node模块，在打包时不会将其打包进二进制文件中，故需要特殊处理，目前是修改源码引用（各位有好的办法可以推荐给我）,然后将.node模块拿到运行目录下： 修改node_modules中对应模块源码的require二进制文件的地方，将其修改为： // 以node-sqlite3为例将lib/sqlite3.js中的var binding = require(binding_path);修改为var binding = require(process.cwd()+'/node_sqlite3.node') 将源码中的node_sqlite3.node文件拷贝到编译后的运行目录，将整个文件夹zip即可在任何地方运行 以上介绍了如何利用pkg进行打包Egg.js工程，如有疑问可以联系作者或者下方评论，一起讨论。QQ: 1016817543 邮箱：1016817543@qq.com github：https://github.com/MrSmallLiu (欢迎star)","categories":[{"name":"后端","slug":"后端","permalink":"http://geocompass.github.io/categories/后端/"}],"tags":[{"name":"Egg.js","slug":"Egg-js","permalink":"http://geocompass.github.io/tags/Egg-js/"}],"author":"LH"},{"title":"关于我们","slug":"about/index","date":"2019-08-20T16:00:00.000Z","updated":"2020-05-21T01:10:32.108Z","comments":true,"path":"2019/08/21/about/index/","link":"","permalink":"http://geocompass.github.io/2019/08/21/about/index/","excerpt":"","text":"关于我们&emsp;&emsp;国信司南（北京）地理信息技术有限公司是国家基础地理信息中心基于促进地理信息产业发展的大局背景，经国家测绘地理信息局批准，于2009年12月成立的全资国有企业。为推进产业发展及地理信息社会化服务，公司相继注资成立了天地图有限公司、国测兴园（北京）投资有限公司。 &emsp;&emsp;公司“以数据获取与处理为核心、以信息化系统建设为抓手、以业务化产品服务为支撑、以管理与技术创新为拓展”，相继为水利、水电、文物、文化、外交、公安、测绘、科技、海关、海事、地质、地震、石油、石化、新闻、出版等领域提供了个性化服务。 &emsp;&emsp;凭借不断提升的技术实力、不断完善的优质服务，公司现已拥有甲级测绘资质、软件企业认定、质量管理体系认证、高新技术企业、计算机信息系统集成企业等资质证书，并荣获多项行业科技、工程、创新类奖项。 &emsp;&emsp;公司拥有一支充满活力、进取创新的高素质团队，秉承“凝心聚力、开拓创新、优质服务、和谐发展”的宗旨，为产业大发展、大繁荣添砖加瓦，为共同推进地理信息更好地服务大局、服务社会、服务民生而努力奋斗。","categories":[{"name":"国信司南","slug":"国信司南","permalink":"http://geocompass.github.io/categories/国信司南/"}],"tags":[{"name":"关于我们","slug":"关于我们","permalink":"http://geocompass.github.io/tags/关于我们/"}],"author":"LOUSANPANG"},{"title":"关于写作","slug":"write/write","date":"2019-08-20T16:00:00.000Z","updated":"2020-05-21T01:10:32.136Z","comments":true,"path":"2019/08/21/write/write/","link":"","permalink":"http://geocompass.github.io/2019/08/21/write/write/","excerpt":"","text":"一、安装1.1 安装前提 Node.js (Should be at least nodejs 6.9) Gitnpm install -g hexo-cli 1.2 下载源码目录git clone https://github.com/geocompass/geocompass.github.io.git 1.3 安装依赖cd geocompass.github.iogit checkout hexonpm install 1.4 编码cd source/_postscd bigdata/ #在对应适合你的文件夹下边建立 博客文档hexo n [Your Blod Name]编码格式请参照 3.1 关于写作 1.5 部署git pull # 建议每次都要更新哦 也许你在书写过程中，有人已经提交code啦手动将子目录的 .git 文件复制粘贴到 .deploy_git 文件中hexo ghexo d在hexo分支提交到远程你的代码例如：git add --agit commit -a -m 'Your name commit pages'git push 二、常见命令2.1 命令 hexo g == hexo generate #生成静态文件 hexo s == hexo server #启动本地web服务 hexo d == hexo deploy #部署播客到远端 hexo clean #清除缓存文件 hexo n == hexo new \"postName\" #新建文章 hexo n == hexo new page \"pageName\" #新建页面 三、关于写作3.1 书写--- title: 关于书写 date: 2019-08-21 categories: 前端 author: LOUSANPANG tags: - React - Webpack cover_picture: /images/banner.jpg top: 0 --- &lt;!-- more --&gt; ### 一、标题一 #### 1.1 标题1.1 说明： 需要注意 tags 和 categories 的写法，不然首页不能正确显示标签和摘要； cover_picture 文章封面图，不填默认显示_config.yml配置的图片。 cover_picture 建议添加符合自己博客的主题图片。 四、详细文档Hexo主题文档 五、常见问题5.1 部署不成功 请严格按照 1.5 部署 流程提交一下你的code, 也许你的问题会解决。 关于为什么要移动 .git文件 请查阅Hexo部署报错Spawn failed及解决方案 部署成功后网站并不是最新的，请清楚一下浏览器缓存，再尝试。 关于你的博客取用图片，你可以建立自己的GitHub图片供应仓库，例如GitHub图片供应库 更多问题请提交Issues 📝","categories":[{"name":"写作","slug":"写作","permalink":"http://geocompass.github.io/categories/写作/"}],"tags":[{"name":"写作","slug":"写作","permalink":"http://geocompass.github.io/tags/写作/"}],"author":"LOUSANPANG"},{"title":"手把手教你用Mapbox的RoboSat基于深度学习自动提取建筑物","slug":"bigdata/robosat-buildings-training-step-by-step","date":"2019-08-16T16:00:00.000Z","updated":"2020-05-21T01:10:32.111Z","comments":true,"path":"2019/08/17/bigdata/robosat-buildings-training-step-by-step/","link":"","permalink":"http://geocompass.github.io/2019/08/17/bigdata/robosat-buildings-training-step-by-step/","excerpt":"","text":"原文链接：https://github.com/geocompass/robosat_buildings_training ​ 本文介绍了如何使用 mapbox/robosat 工具，基于深度学习训练，从常规的遥感影像瓦片地图服务中自动提取建筑物。包括系统准备工作、数据准备工作和训练与建模。通过根据文章的描述，可以完成训练任务。 ​ 参考文章：daniel-j-h : RoboSat ❤️ Tanzania 手把手教你如何使用 RoboSat 自动提取建筑物 1. 系统准备工作 1.1 设备及系统 1.2 安装 Docker 1.3 在 Docker 中安装 Robosat 2. 数据准备工作 2.1 建筑物轮廓矢量数据 2.2 获取建筑物轮廓geojson数据 2.3 提取训练区覆盖的瓦片行列号 2.4 下载训练区遥感影像瓦片 2.5 制作训练区矢量数据蒙版标记 3. 训练和建模 3.1 分配训练数据、验证数据、评估数据 3.2 权重计算 3.3 开始训练 4. 预测 4.1 准备预测区域数据 4.2 预测待提取建筑物概率 4.3 预测概率转换为建筑物掩模 4.4 建筑物掩模转换为geojson 4.5 合并掩模分割的 geojson ​ 参考文章：daniel-j-h : RoboSat ❤️ Tanzania 1. 系统准备工作1.1 设备及系统 准备一台安装 Linux 或 MacOS 系统的机器，可以是 CentOS、Ubuntu 或 MacOS。机器可以是实体机，也可以是 VMware 虚拟机。 1.2 安装 Docker 在机器中安装 Docker，不建议是 Windows 版 Docker。MacOS 安装 Docker ，CentOS 安装 Docker 1.3 在 Docker 中安装 Robosat Robosat 的 Docker Hub。 ​ 可以使用两种方式安装 Robosat： 使用 CPU 容器： docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu --help 使用 GPU 容器（主机上需要 nvidia-docker）： docker run --runtime=nvidia -it --rm -v $PWD:/data --ipc=host mapbox/robosat:latest-gpu train --model /data/model.toml --dataset /data/dataset.toml --workers 4 2. 数据准备工作2.1 建筑物轮廓矢量数据​ 已有的建筑物轮廓矢量数据用来作为建筑物提取的训练数据源。可以有两种方式获取： OSM 数据源，可以在 geofabrik 获取，通过 osmium 和 robosat 工具进行处理。 自有数据源。通过 QGIS 或 ArcMap 等工具，加载遥感影像底图，描述的建筑物轮廓 Shapefile 数据。 ​ 本文使用第二种数据来源，并已开源数据源，开源的矢量数据覆盖厦门核心区。 ​ 考虑到使用个人电脑没有 CUDA 加速训练成本较高，本文使用 buia_xiamen_min_shp，包含厦门核心区部分区域，共 5679 个建筑物轮廓。在 Docker 配置为 处理器(CPU) 4 核、内存(RAM)16GB、交换内存(Swap)3GB 时，训练时间大约 2.5 小时。 2.2 获取建筑物轮廓 geojson 数据​ 通过在线工具 mapshaper，将 shapefile 数据转换为 geojson 数据。 2.3 提取训练区覆盖的瓦片行列号​ 使用 robosat 的 cover 命令，即可获取当前训练区矢量数据覆盖的瓦片行列号，并使用 csv 文件存储。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu cover --zoom 18 /data/buildings.json /data/buildings.tiles cover 命令的参数介绍： usage: ./rs cover [-h] --zoom ZOOM features out positional arguments: features path to GeoJSON features out path to csv file to store tiles in optional arguments: -h, –help show this help message and exit --zoom ZOOM zoom level of tiles (default: None) 这里是获取在 18 级下训练区覆盖的瓦片行列号。18 级是国内地图通用的最大级别，如果有国外更清晰数据源，可设置更高地图级别。 ​ cover 工具对训练区矢量数据计算的瓦片行列号使用的是通用的 WGS84-&gt;Web 墨卡托投影坐标系。 小知识： $PWD:/data 是将当前路径映射为 docker 中的 /data 路径。 在新版 robosat 的 docker 安装包中，将 ./rs 命令行工具对应为docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu 命令。 docker 版 robosat ，以命令行方式执行，无法生成类似 nginx 的 docker 服务，所以执行完成后立即销毁了 docker 的 container。 2.4 下载训练区遥感影像瓦片​ 使用 robosat 的 download 工具，即可获取当前训练区矢量数据覆盖的遥感影像，下载的瓦片通过 2.3 节中的buildings.tiles 确定。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu download http://ditu.google.cn/maps/vt/lyrs=s&amp;x=&#123;x&#125;&amp;y=&#123;y&#125;&amp;z=&#123;z&#125; /data/buildings.tiles /data/tiles ​ download 命令的参数介绍： usage: ./rs download [-h] [--ext EXT] [--rate RATE] url tiles out positional arguments: url endpoint with {z}/{x}/{y} variables to fetch image tiles from tiles path to .csv tiles file out path to slippy map directory for storing tiles optional arguments: -h, –help show this help message and exit --ext EXT file format to save images in (default: webp) --rate RATE rate limit in max. requests per second (default: 10) ​ 这里介绍几个常用的 Web 墨卡托投影的（WGS84 坐标系）遥感影像数据源： 谷歌地图 CN 影像：http://ditu.google.cn/maps/vt/lyrs=s&amp;x={x}&amp;y={y}&amp;z={z} 天地图影像：https://t4.tianditu.gov.cn/DataServer?T=img_w&amp;x={x}&amp;y={y}&amp;l={z}&amp;tk=2ce94f67e58faa24beb7cb8a09780552 ArcGIS Online 影像：https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x} MapBox 影像：https://api.mapbox.com/v4/mapbox.satellite/{z}/{x}/{y}@2x.png?sku=101KOLcQaDwG1&amp;access_token=[token] ​ 几种遥感影像数据源的比较： 从访问速度来看，天地图&gt;谷歌&gt;ArcGIS&gt;Mapbox。 从遥感影像的质量来说，总体来说： 城市地区：谷歌=ArcGIS&gt;天地图&gt;Mapbox 农村地图：谷歌&gt;天地图&gt;ArcGIS&gt;Mapbox 层级覆盖：谷歌&gt;天地图&gt;ArcGIS&gt;Mapbox ​ 不同影像数据源的质量不能一概而论，由于传感器不同、过境时间不同等因素，不同地区的影像数据源质量均不同，建议使用 QGIS 加载训练区位置的影像对比选择。 2.5 制作训练区矢量数据蒙版标记​ 使用 2.2 节中制作的 geojson 数据，通过 robosat 的 rasterize 工具可制作训练区矢量数据的蒙版标记数据。蒙版标记数据与瓦片数据一一相对应，使用同样的 buildings.tiles 瓦片列表产生。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu rasterize --dataset /data/dataset-building.toml --zoom 18 --size 256 /data/buildings.json /data/buildings.tiles /data/masks ​ rasterise 命令的参数介绍： usage: ./rs rasterize [-h] --dataset DATASET --zoom ZOOM [--size SIZE] features tiles out positional arguments: features path to GeoJSON features file tiles path to .csv tiles file out directory to write converted images optional arguments:-h, --help show this help message and exit--dataset DATASET path to dataset configuration file (default: None)--zoom ZOOM zoom level of tiles (default: None)--size SIZE size of rasterized image tiles in pixels (default: 512) 这里使用到了 dataset-building.toml 配置文件，文件中配置了瓦片地图路径、分类方式、蒙版标记的颜色等信息。示例配置可以查看官方示例文件 dataset-parking.toml 。本训练中用到的 dataset-building.toml 的配置内容如下： # Configuration related to a specific dataset.# For syntax see: https://github.com/toml-lang/toml#table-of-contents# Dataset specific common attributes.[common] # The slippy map dataset's base directory. dataset = '/Users/wucan/Document/robosat/tiles/' # Human representation for classes. classes = ['background', 'buildings'] # Color map for visualization and representing classes in masks. # Note: available colors can be found in `robosat/colors.py` colors = ['denim', 'orange'] ​ 配置文档中，最重要的是配置 dataset 目录，也就是上一步中下载的遥感影像瓦片路径。制作的蒙版标记效果如下图。 ​ 至此，训练和建模所需的瓦片和蒙版标记已经全部准备完，分别在 tiles 和 masks 目录中。 3. 训练和建模3.1 分配训练数据、验证数据、评估数据​ RoboSat 分割模型是一个完全卷积的神经网络，需要将上一步准备好的数据集拆分为三部分，分别为训练数据集 、验证数据集、评估数据集，比例分别为 80%、10%、10%。每一部分的数据集中，都包含影像瓦片和蒙版标记瓦片。 训练数据集：a training dataset on which we train the model on 验证数据集：a validation dataset on which we calculate metrics on after training 评估数据集：a hold-out evaluation dataset if you want to do hyper-parameter tuning 将步骤 2 中的数据进行随机分配的过程非常简单： 新建三个 csv 文件： csv_training.tiles 、csv_validation.tiles、 csv_evaluation.tiles 将 buildings.tiles 中的瓦片列表随机按 80%、10%、10% 比例进行拷贝与粘贴。注意三个文件间的瓦片列表内容不能重复。 ​ 使用 RoboSat 中的 subset 命令，将 tiles 和 masks 中的瓦片和蒙版按照上面三个 csv 文件的瓦片列表分配进行组织影像瓦片和蒙版标记数据。 # 准备训练数据集docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu subset /data/tiles/ /data/csv_training.tiles /data/dataset/training/imagesdocker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu subset /data/masks/ /data/csv_training.tiles /data/dataset/training/labels# 准备验证数据集docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu subset /data/tiles/ /data/csv_validation.tiles /data/dataset/validation/imagesdocker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu subset /data/masks/ /data/csv_validation.tiles /data/dataset/validation/labels# 准备评估数据集docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu subset /data/tiles/ /data/csv_evaluation.tiles /data/dataset/evaluation/imagesdocker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu subset /data/masks/ /data/csv_evaluation.tiles /data/dataset/evaluation/labels ​ subset 命令的参数介绍： usage: ./rs subset [-h] images tiles out positional arguments: images directory to read slippy map image tiles from for filtering tiles csv to filter images by out directory to save filtered images to optional arguments: -h, --help show this help message and exit ​ 分类完成以后，将会生成 /data/dataset 目录，目录结构如下： dataset| training| | images| | labels| validataion| | images| | labels| evaluation| | images| | labels 3.2 权重计算​ 因为前景和背景在数据集中分布不均，可以使用 RoboSat 中的 weights 命令，在模型训练之前计算一下每个类的分布。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu weights --dataset /data/dataset-building-weights.toml ​ weights 命令的参数如下： usage: ./rs weights [-h] --dataset DATASET optional arguments: -h, --help show this help message and exit --dataset DATASET path to dataset configuration file (default: None) ​ 这里，用到了dataset-building-weights.toml ，是将前面步骤中的 dataset-building.toml 瓦片路径修改为包含训练数据集 dataset 的路径。执行权重计算命令后，得到权重为：values = [1.653415, 5.266637] 。将其追加到 dataset-building-weights.toml 文件中，结果如下。 # Configuration related to a specific dataset.# For syntax see: https://github.com/toml-lang/toml#table-of-contents# Dataset specific common attributes.[common] # The slippy map dataset&apos;s base directory. dataset = &apos;/data/dataset&apos; # Human representation for classes. classes = [&apos;background&apos;, &apos;buildings&apos;] # Color map for visualization and representing classes in masks. # Note: available colors can be found in `robosat/colors.py` colors = [&apos;denim&apos;, &apos;orange&apos;]# Dataset specific class weights computes on the training data.# Needed by &apos;mIoU&apos; and &apos;CrossEntropy&apos; losses to deal with unbalanced classes.# Note: use `./rs weights -h` to compute these for new datasets.[weights] values = [1.653415, 5.266637] 3.3 开始训练​ RoboSat 使用 train 命令进行训练。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu train --model /data/model-unet.toml --dataset /data/dataset-building-weights.toml ​ train 命令的参数如下： usage: ./rs train [-h] --model MODEL --dataset DATASET [--checkpoint CHECKPOINT] [--resume RESUME] [--workers WORKERS] positional arguments: --model MODEL path to model configuration file (default: None) --dataset DATASET path to dataset configuration file (default: None) optional arguments: -h, `–help show this help message and exit --checkpoint CHECKPOINT path to a model checkpoint (to retrain) (default: None) --resume RESUME resume training or fine-tuning (if checkpoint) (default: False) --workers WORKERS number of workers pre-processi ng images (default: 0) ​ 这里多了一个配置文件 model-unet.toml ，这个配置文件主要用来配置训练过程中的参数，包括是否启用 CUDA 、训练批次大小、影像瓦片的像素大小、检查点存储路径等。官方给出了示例配置文件，根据本实验的情况做了修改如下，配置如下。 # Configuration related to a specific model.# For syntax see: https://github.com/toml-lang/toml#table-of-contents# Model specific common attributes.[common] # Use CUDA for GPU acceleration. cuda = false # Batch size for training. batch_size = 2 # Image side size in pixels. image_size = 256 # Directory where to save checkpoints to during training. checkpoint = &apos;/data/checkpoint/&apos;# Model specific optimization parameters.[opt] # Total number of epochs to train for. epochs = 10 # Learning rate for the optimizer. lr = 0.01 # Loss function name (e.g &apos;Lovasz&apos;, &apos;mIoU&apos; or &apos;CrossEntropy&apos;) loss = &apos;Lovasz&apos; ​ RoboSat 会进行多次迭代训练，每次迭代训练都会保存检查点(checkpoint)和各项指标等。其中，训练日志例如： --- Hyper Parameters on Dataset: /data/dataset ---Batch Size: 2Image Size: 256Learning Rate: 0.0001Loss function: LovaszWeights : [1.644471, 5.409126]---Epoch: 1/10Train loss: 0.3190, mIoU: 0.410, buildings IoU: 0.017, MCC: -0.002Validate loss: 0.3171, mIoU: 0.405, buildings IoU: 0.000, MCC: nan...Epoch: 10/10Train loss: 0.2693, mIoU: 0.528, buildings IoU: 0.229, MCC: 0.330Validate loss: 0.2880, mIoU: 0.491, buildings IoU: 0.167, MCC: 0.262 ​ 可以选择最好的训练结果，保留其检查点( checkpoint-***.pth )，进入下一步 predict。一般来说，最后一个检查点效果最好。 4. 预测4.1 准备预测区域数据​ RoboSat 仅支持从影像瓦片中提取建筑物，不支持从任意的 jpg 图片中提取。所以我们需要先准备预测区域的瓦片数据。 ​ 通过 geojson.io 绘制想要提取建筑物的范围，使用矩形框即可。将自动生成的 geojson 保存为 predict_test.json。 ​ 通过 2.3 中的 cover 命令，获取待提取范围的瓦片列表 csv 文件，保存到 buildings_predict.tiles 文件中。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu cover --zoom 18 /data/shp_data/predict_test.json /data/buildings_predict.tiles ​ 使用 2.4 中的 download 命令，下载待提取范围的影像瓦片，保存到 images_predict 文件夹中。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu download https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/&#123;z&#125;/&#123;y&#125;/&#123;x&#125; /data/buildings_predict.tiles /data/images_predict 4.2 预测待提取建筑物概率​ 使用保存的检查点来（checkpint）预测图像中每个像素的分割概率，这些分割概率表示每个像素是建筑物还是背景的可能性，然后可以将这些概率转换为离散的分割掩模。 ​ 通过 RoboSat 的 predict 命令，将待预测区域的建筑物（ images_predict ）提取为分割概率（predict_segmentation-probabilities）。 docker run -it -d --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu predict --tile_size 256 --model /data/model-unet.toml --dataset /data/dataset-building.toml --checkpoint /data/checkpoint/checkpoint-00010-of-00010.pth /data/images_predict /data/predict_segmentation-probabilities ​ predict 命令的参数如下： usage: ./rs predict [-h] [--batch_size BATCH_SIZE] --checkpoint CHECKPOINT [--overlap OVERLAP] --tile_size TILE_SIZE [--workers WORKERS] --model MODEL --dataset DATASET tiles probs positional arguments: tiles directory to read slippy map image tiles from probs directory to save slippy map probability masks to optional arguments: -h, --help show this help message and exit --batch_size BATCH_SIZE images per batch (default: 1) --checkpoint CHECKPOINT model checkpoint to load (default: None) --overlap OVERLAP tile pixel overlap to predict on (default: 32) --tile_size TILE_SIZE tile size for slippy map tiles (default: None) --workers WORKERS number of workers pre-processing images (default: 0) --model MODEL path to model configuration file (default: None) --dataset DATASET path to dataset configuration file (default: None) 4.3 预测概率转换为建筑物掩模​ 通过 RoboSat 的 masks 命令，将上一步中的建筑物预测概率结果转换为建筑物掩模（masks），保存到 predict_segmentation-masks 文件夹中。 docker run -it -d --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu masks /data/predict_segmentation-masks /data/predict_segmentation-probabilities usage: ./rs masks [-h] [--weights WEIGHTS [WEIGHTS ...]] masks probs [probs ...] positional arguments: masks slippy map directory to save masks to probs slippy map directories with class probabilities optional arguments: -h, --help show this help message and exit --weights WEIGHTS [WEIGHTS ...] weights for weighted average soft-voting (default:None) 4.4 建筑物掩模转换为 geojson​ 通过 RoboSat 的 features 命令，将上一步中的建筑物掩模转换为 geojson，保存在 predict_geojson_features 文件夹中。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu features /data/predict_segmentation-masks /data/predict_geojson_features usage: ./rs features [-h] --type {parking} --dataset DATASET masks out positional arguments: masks slippy map directory with segmentation masks out path to GeoJSON file to store features in optional arguments: -h, --help show this help message and exit --type {parking} type of feature to extract (default: None) --dataset DATASET path to dataset configuration file (default: None) （目前 features 命令中对 --type 设置有 bug，无法正常执行。） 4.5 合并掩模分割的 geojson​ 通过 RoboSat 的 merge 命令，将上一步中生成的分割的 geojson 要素进行合并，结果保存在 predict_geojson_merge文件夹中。 docker run -it --rm -v $PWD:/data --ipc=host --network=host mapbox/robosat:latest-cpu features /data/predict_geojson /data/predict_geojson_merge usage: ./rs merge [-h] --threshold THRESHOLD features out positional arguments: features GeoJSON file to read features from out path to GeoJSON to save merged features to optional arguments: -h, --help show this help message and exit --threshold THRESHOLD minimum distance to adjacent features, in m (default:None)","categories":[{"name":"大数据","slug":"大数据","permalink":"http://geocompass.github.io/categories/大数据/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://geocompass.github.io/tags/大数据/"}]}]}